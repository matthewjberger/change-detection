{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the images in gray scale\n",
        "img1 = cv2.imread('images/scene_with_candy.jpg', 0)\n",
        "img2 = cv2.imread('images/scene_with_candy_2.jpg', 0)\n",
        "\n",
        "# Detect the SIFT key points and compute the descriptors for the two images\n",
        "sift = cv2.xfeatures2d.SIFT_create()\n",
        "keyPoints1, descriptors1 = sift.detectAndCompute(img1, None)\n",
        "keyPoints2, descriptors2 = sift.detectAndCompute(img2, None)\n",
        "\n",
        "# Create brute-force matcher object\n",
        "bf = cv2.BFMatcher()\n",
        "\n",
        "# Match the descriptors\n",
        "matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "# Select the good matches using the ratio test\n",
        "goodMatches = []\n",
        "\n",
        "for m, n in matches:\n",
        "    if m.distance < 0.7 * n.distance:\n",
        "        goodMatches.append(m)\n",
        "\n",
        "# Apply the homography transformation if we have enough good matches \n",
        "MIN_MATCH_COUNT = 10\n",
        "\n",
        "if len(goodMatches) > MIN_MATCH_COUNT:\n",
        "    # Get the good key points positions\n",
        "    sourcePoints = np.float32([ keyPoints1[m.queryIdx].pt for m in goodMatches ]).reshape(-1, 1, 2)\n",
        "    destinationPoints = np.float32([ keyPoints2[m.trainIdx].pt for m in goodMatches ]).reshape(-1, 1, 2)\n",
        "    \n",
        "    # Obtain the homography matrix\n",
        "    M, mask = cv2.findHomography(sourcePoints, destinationPoints, method=cv2.RANSAC, ransacReprojThreshold=5.0)\n",
        "    matchesMask = mask.ravel().tolist()\n",
        "    \n",
        "    # Apply the perspective transformation to the source image corners\n",
        "    h, w = img1.shape\n",
        "    corners = np.float32([ [0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0] ]).reshape(-1, 1, 2)\n",
        "    transformedCorners = cv2.perspectiveTransform(corners, M)\n",
        "    \n",
        "    # Draw a polygon on the second image joining the transformed corners\n",
        "    img2 = cv2.polylines(img2, [np.int32(transformedCorners)], True, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "else:\n",
        "    print(\"Not enough matches are found - %d/%d\" % (len(goodMatches), MIN_MATCH_COUNT))\n",
        "    matchesMask = None\n",
        "\n",
        "# Draw the matches\n",
        "drawParameters = dict(matchColor=(0, 255, 0), singlePointColor=None, matchesMask=matchesMask, flags=2)\n",
        "result = cv2.drawMatches(img1, keyPoints1, img2, keyPoints2, goodMatches, None, **drawParameters)\n",
        "\n",
        "# Display the results\n",
        "#plt.axis(\"off\")\n",
        "#plt.imshow(result, extent=[0,400,0,1], aspect='auto')\n",
        "#plt.show()\n",
        "\n",
        "# Display the results\n",
        "cv2.imshow('Homography', result)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the images in gray scale\n",
        "img1 = cv2.imread('images/scene_with_candy.jpg', 0)\n",
        "img2 = cv2.imread('images/scene_with_candy_2.jpg', 0)\n",
        "\n",
        "saliencyDetector = cv2.saliency.StaticSaliencySpectralResidual_create()\n",
        "img1Values = saliencyDetector.computeSaliency(img1, None)\n",
        "img2Values = saliencyDetector.computeSaliency(img2, None)\n",
        "\n",
        "img1Values[1].shape\n",
        "result = (img1Values[1] > 0.16) * img1Values[1]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 54,
          "data": {
            "text/plain": [
              "array([[ 0.16611283,  0.16611283,  0.16611283, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.16611283,  0.16611283,  0.16611283, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.16611283,  0.16611283,  0.16611283, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ..., \n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]], dtype=float32)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 54,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.3.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}